{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e79d44-fd02-41c5-9497-6a3f1f8f8ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "import dill\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.style.use(\"Solarize_Light2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3081f30-e4d4-4ac3-98ad-770c944ecb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! py -3.11 -m pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a0b72-e4e1-4723-8589-7727b5bedbf3",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "* The goal is to perform sentiment analysis on the reviews.\n",
    "\n",
    "* Instead of directly predicting ratings (1–5), we map ratings into 3 sentiment categories:\n",
    "\n",
    "#### 1. Ratings 1–2 → Negative \n",
    "\n",
    "#### 2. Rating 3 → Neutral \n",
    "\n",
    "#### 3. Ratings 4–5 → Positive \n",
    "\n",
    "* This converts the task into a 3-class text classification problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a439e2c-5dae-4ca9-9fb0-07540e777be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab38a64d-fd6c-40f9-b98f-144ed2848657",
   "metadata": {},
   "source": [
    "# Input Features\n",
    "\n",
    "#### Title (short text)\n",
    "\n",
    "#### Body (detailed review text)\n",
    "\n",
    "#### These will be combined or individually used as text input to the NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ead6bf1-4c90-4dde-aea9-3c2b7fdda649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91e08882-e02b-403a-909b-defe0e39d542",
   "metadata": {},
   "source": [
    "# Target Feature\n",
    "\n",
    "* The target variable is Sentiment, which is derived from the Rating.\n",
    "\n",
    "## Mapping logic :\n",
    "\n",
    "#### 1 or 2 → Negative\n",
    "\n",
    "#### 3 → Neutral\n",
    "\n",
    "#### 4 or 5 → Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b2f740-76cc-4b01-91e5-99bb9598e115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d03a2b4a-9d57-4c84-bd41-98ad4e95aa54",
   "metadata": {},
   "source": [
    "# Loading Dataset from Excel into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71e25e-302f-4cc9-9b6b-8134ef797733",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_sheets = pd.ExcelFile(\"dataset -P582.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22cc08-9861-4db6-a5f3-e7e430953a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_sheets.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0729977-f234-4f91-bfc2-925d113ba42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"dataset -P582.xlsx\", sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9105722-d5fd-40d2-9369-1b7392e28279",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb3f6d-3e61-49e4-b689-d102dcf6faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # There are 1440 rows and 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6199eb-62a2-4252-aabc-44f500557757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ce465-8661-4ef6-a6c2-27a92dfdea36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e250008-14f8-4076-9385-78d845c114db",
   "metadata": {},
   "source": [
    "# Deriving the Sentiment Feature from Ratings Feature\n",
    "* We derived a new column sentiment from the original rating column at the beginning of the workflow. This ensures that the dataset directly reflects the 3-class sentiment classification problem (Negative, Neutral, Positive), which is the actual objective of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31324ab1-3be3-4106-84e8-a644bacdf507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(rating):\n",
    "    if rating in [1,2]:\n",
    "        return \"Negative\"\n",
    "    elif rating == 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\"\n",
    "\n",
    "df[\"sentiment\"] = df[\"rating\"].apply(map_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08f7b7-2c0e-4172-b3c5-1099cbb99556",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"rating\", axis=1)   # Droped Rating feature beacause we derived new featrue from rating feature the is sentement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8ef01-6014-45a9-a04f-89ee476722b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "441718f2-2aad-4b61-95b3-76f196cf4523",
   "metadata": {},
   "source": [
    "# Combining Title and Body for Text Analysis\n",
    "* We combined the title and body into a single review column since both convey the same review. This reduces extra preprocessing and gives the model full context, often improving accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae123c-eb47-4d77-9d9a-19f1784a81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"title\"] + \" \" + df[\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d91040-9a11-492b-96c3-f5f00320c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"title\",\"body\"],axis = 1) # Droped title and body feature beacause we combine these feature to make new feature that is review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ddfa5-b10b-486b-b2d5-de388696e3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f11f5ee0-d6f3-4f20-bf69-2441d90d95cb",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87588115-dfae-4037-91f4-265b04235e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "905c6ea1-ea87-4c47-b2fd-bad41f2c4e17",
   "metadata": {},
   "source": [
    "# Step 1: Initial Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643420c2-7a89-47dc-a2b8-d1e54b6624ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fe22f-4382-41dd-9c17-1c53d3888468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3dc42e-ebb7-4eec-a11d-a5a6132c62d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape  # There are 1440 rows and 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9527c7-95f0-4b58-b0f6-07c814a18738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac7d15-9b0b-4785-a675-64846614c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bcb486-d1aa-43a6-93ee-b1ce7cd40950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2425a-4143-45cb-9d68-9284a840d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7f305-75f3-48e1-888c-ebfad7c56173",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In sentment feature have {df.sentiment.nunique()} uniques values and those are {df.sentiment.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212245e0-79a0-44b2-a5b5-1c434d2f9f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c97df54-8b4c-41e1-9c31-a99b8c07e2bf",
   "metadata": {},
   "source": [
    "# Step 2: Checking Null Values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b268e7-ae85-4fa3-9662-e53cb1a70276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d62205-fa22-4ed8-a603-d70f78fe8b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc4eff26-847c-4151-8897-9073aa50dd8b",
   "metadata": {},
   "source": [
    "# Step 3: Checking Duplicates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7735c3bf-84a1-494d-aef1-548a242ad45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7eacd-4110-4925-8bd4-c402cf6460c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dec31cb-e0b7-484b-be11-3244a21a4ed1",
   "metadata": {},
   "source": [
    "# Step 4: Data type conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645788e-4fa5-4be7-bced-79c2b8d171d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"] = df[\"sentiment\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66259a5-4b52-48c6-a002-918477ec0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26899e-6517-4407-9ae7-32a37fbfc0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24305e8f-2fe7-4e6a-96d4-10ff32d3fa19",
   "metadata": {},
   "source": [
    "# Step 5: Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c35bb-46ea-43b3-aec2-c1e6d599613c",
   "metadata": {},
   "source": [
    "## 1.  Sentiment Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba7c78-a562-46f3-9522-0e36eea56523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faffcde1-71e1-435b-8733-53b9c8d5d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"Set2\", n_colors=df['sentiment'].nunique())\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x = \"sentiment\", data = df,palette = palette, hue=\"sentiment\" ,edgecolor=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1aea1b-40ec-4201-8a55-32fb59dd50c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c67b330-be01-46d0-8c94-308a4a557990",
   "metadata": {},
   "source": [
    "## 2. Review Length Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90052dc5-6110-4795-bc77-6cdde4bb9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review_length\"] = df[\"review\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df[\"review_length\"], bins=30, kde=True, color=\"skyblue\")\n",
    "plt.title(\"Review Length Distribution (in words)\")\n",
    "plt.xlabel(\"Review Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b411ab-a192-4e8f-bfe1-3ef0c3d1b040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c44c47a-253d-41dd-a152-417e8631e1e1",
   "metadata": {},
   "source": [
    "# Step 6: Multivariate analysis: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12394682-76c0-4024-989d-84b901a088f4",
   "metadata": {},
   "source": [
    "## 1. Review Length Distribution per Sentiment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db6be8-e2c6-48ce-9a81-968d38dc1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(data=df, x='sentiment', y='review_length', palette=\"Set2\", hue = \"sentiment\")\n",
    "plt.title(\"Review Length vs Sentiment\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Review Length (in words)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f69dc-be7e-4d8c-9588-8f250885836b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e65579f-0b3b-4649-98a0-c840be85ae48",
   "metadata": {},
   "source": [
    "# Insights from EDA : \n",
    "* In this dataset there are 3 Columns and 1440 rows are there\n",
    "* Feature 1: ['title'] and its data type is object, This feature is short summary of Review \n",
    "* Feature 2: ['Rating'] and its data type is descrit numerical column, Rating of the product accroding to review\n",
    "* Feature 3: [body] and its data type is object, This feature is long text explaining the review\n",
    "* we combine the title and body features to make new feature called Review\n",
    "* And also we Deriving new Feature from the Rating featrue called Sentiment \n",
    "* In this dataset there is no null vlaues are there as well as there is no duplicated row are present in this dataset\n",
    "* In sentment feature have 3 uniques values and those are ['Negative' 'Neutral' 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c775e-0c81-4607-9006-a79db2fd401e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddae77e-47f2-43fc-90f4-585cfadeed6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bda220-639f-4eb1-850a-7bfd01b10923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a0100e9-c05d-4509-a5f6-d3f9ed77e481",
   "metadata": {},
   "source": [
    "# Text Preprocessing for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0dd31c-915a-4fa8-92b8-43672b4a49c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e6e30d7-493a-4fd3-a743-7127336bb032",
   "metadata": {},
   "source": [
    "# Step 1: Lowercasing & Removing Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04894341-cbdf-4c4a-932f-1b22380ae910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa1880d-9dd2-493b-a95d-c99d619677f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()                                   # lowercase\n",
    "    text = re.sub(r'<.*?>', '', text)                     # remove HTML\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)            # remove URLs\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)                  # keep only letters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()              # remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0661af61-d51c-451c-9892-bc053a9fe974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea7672-c3c5-4bab-9746-74025039da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = df[\"review\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29438119-48ba-45c1-9bf7-7abff5d1f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fe2015-7117-4ccf-ba98-6d45db36bcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3d122c0-dcdc-45f8-a21e-421e250dcb4a",
   "metadata": {},
   "source": [
    "# Step 2: Tokenization + Stopword Removal\n",
    "\n",
    "## Why we remove stopwords and what is stop words\n",
    "* We removed stopwords (common words like ‘the’, ‘is’, ‘and’) because they do not carry meaningful information for sentiment analysis and only add noise to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd607ee5-c7bd-40c9-b72a-91a356978c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Download stopwords if not already\n",
    "nltk.download('punkt')     # for tokenization (word_tokenize)\n",
    "nltk.download('stopwords') # downloading the all stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255df6b-a7f3-49ad-b78e-1335f4be9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933157f-17d1-4d2e-aea2-8673e7945ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d20fb32-eefe-42ac-8073-fccf3b7c1ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_remove_stopwords(review):\n",
    "    tokens = word_tokenize(review)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5013282-e826-4eae-a7d8-8e1f8a4f04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['clean_text'].apply(tokenize_and_remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c5ca2-0c7e-42f0-9b72-222f25e09426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['clean_text','tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab6de0-5c7c-402d-b4c6-c6c26acc31a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eb33876-8ff2-499e-8215-ccc6f1c50315",
   "metadata": {},
   "source": [
    "# Word Frequency Analysis of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea7479-8b6f-4f9d-a32f-fbb1591e5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = df['tokens'].tolist()\n",
    "\n",
    "all_words = []\n",
    "for words_list in tokens:\n",
    "    for word in words_list: \n",
    "        all_words.append(word)\n",
    "\n",
    "word_freq = Counter(all_words).most_common(20)\n",
    "words, counts = zip(*word_freq)\n",
    "\n",
    "for i in range(len(counts)):\n",
    "    print(f\"{words[i]} - {counts[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8289ce-d2ee-49e3-8d75-3818cd4d8d1e",
   "metadata": {},
   "source": [
    "# Visualizing Most Frequent Words Using Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89423a72-5e23-4149-a6c8-98b2175553f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=list(counts), y=list(words), palette=\"viridis\")\n",
    "plt.title(\"Top 20 Most Frequent Words\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07078f9f-1229-4164-a4fc-d568c171cbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b26f34fe-1bda-4f6c-8422-6f14844f2fe4",
   "metadata": {},
   "source": [
    "# Visualizing Most Frequent Words by Sentiment -> Word Clouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f124d16-d91c-43d5-a961-9d847e6025c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "for sentiment in df[\"sentiment\"].unique():\n",
    "    text = \" \".join(df[df[\"sentiment\"] == sentiment][\"review\"])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)\n",
    "\n",
    "    print(f\"Word Cloud for {sentiment} Reviews: \")\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud for {sentiment} Reviews\")\n",
    "    plt.show()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bbf801-1a81-44f1-8308-0d24b9ef4b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e218cb66-5884-4af7-a126-62fcf5333ba6",
   "metadata": {},
   "source": [
    "# Step 3: Text Normalization (Lemmatization/Stemming)\n",
    "* We applied lemmatization to reduce words to their base form (e.g., ‘running’ → ‘run’). This helps the model focus on meaning rather than word variations.\n",
    "  \n",
    "#### \"J\" → Adjective\n",
    "\n",
    "#### \"N\" → Noun\n",
    "\n",
    "#### \"V\" → Verb\n",
    "\n",
    "#### \"R\" → Adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa3e53-cd6d-4d83-ab94-5cb06eef65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! py -3.11 -m pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b052f-cc51-4e98-ad87-ead65bb5ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! py -3.11 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420229b1-2e25-4f52-bebe-38084deeeec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def lemmatize_tokens_spacy(tokens):\n",
    "    doc = nlp(\" \".join(tokens))   # join tokens back into a sentence for spaCy\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "# Example: if you already have a column \"tokens\"\n",
    "df[\"review_lemmatized\"] = df[\"tokens\"].apply(lemmatize_tokens_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c5ae7-6b6d-4c4d-9535-a679c016f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"tokens\",\"review_lemmatized\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833663cf-b10c-4082-b919-95485b2fde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ccd14e-9ea7-4d22-b7a9-4c5aff357e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fdcc925-1380-4ee6-8c82-6b909a8ff70f",
   "metadata": {},
   "source": [
    "# VADER-based sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc732c-11a8-424f-97d4-7a989260fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !py -3.11 -m pip install vaderSentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05af15c-d66c-433b-8fff-9e20275bd1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ddb4a-bc00-4173-b904-7e9fc82b1089",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_sentiment(token):\n",
    "    text = \" \".join(token)\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif compound <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf974c4-340c-4c69-aae2-33c747a5181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader_sentiment'] = df['review_lemmatized'].apply(get_vader_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e17f4-0fb6-4a9a-b257-e9e878a1b632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea70c44-8e8f-4d70-9f1b-2de5b6954d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afa5a577-2773-4eec-9b36-ab31c71e3814",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency – Inverse Document Frequency) Vectorization:\n",
    "* We converted the preprocessed reviews into numerical vectors using TF-IDF, where each word is represented by its importance in the review relative to the corpus, resulting in a DataFrame ready for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e1010-961a-4fd1-8a5f-df294b19fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39397aa7-0e52-4ef3-a250-b248d012ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join lemmatized tokens back into a sentence\n",
    "df[\"review_text\"] = df[\"review_lemmatized\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d376da5-ee33-47e5-b0b7-5b1860b8e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=2000)  # you can adjust max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d93a1c4-7eb8-4ae6-8330-038deb87d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the text\n",
    "X = tfidf.fit_transform(df[\"review_text\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd276c50-be09-49c7-b4ea-4ff6f9b7664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame with feature names as columns\n",
    "tfidf_df = pd.DataFrame(X, columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01af6793-5e00-442c-b904-51ebb578ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: add the target sentiment column back\n",
    "tfidf_df[\"sentiment\"] = df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714db027-03ec-47fe-853b-1dd48cdb8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422bb3d-aa97-4f4b-b8cc-61dcd3d40c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a38a46-3e24-4680-a6c6-4163ca0d929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../models/tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(tfidf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc50213-b396-40c2-bb8c-4e19b9e3886e",
   "metadata": {},
   "source": [
    "# Encoding the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d5dcc-4c4a-43ef-ad4c-040873c74d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map sentiment to numerical values in the original DataFrame\n",
    "sentiment_mapping = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "tfidf_df[\"sentiment_num\"] = tfidf_df[\"sentiment\"].map(sentiment_mapping)\n",
    "\n",
    "# Check\n",
    "tfidf_df[[\"sentiment\", \"sentiment_num\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7b0886-829d-4ec9-854a-5573f42c2ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cf05b6b-121d-47cd-be53-786734b34ab9",
   "metadata": {},
   "source": [
    "# Final Preprocessed Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ac381-2744-46f2-9e68-97e54c16a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d102a8-7dc2-4a43-b951-a00714a95a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5ea6c-2763-4e58-842c-70dd0d8679a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fd37499-5d39-4926-8278-7db2557ac959",
   "metadata": {},
   "source": [
    "# Splitting Dataset into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5332aa-dfba-47be-9797-52ce7bac13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_df.drop(columns=['sentiment','sentiment_num'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe6241c-54c8-4311-86f1-0e026bf4cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ebbc9-e8c8-4191-a1db-d9244884510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733f07c6-4128-4cfa-913c-7c25f5ddbf66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb8e21-46bb-4c38-aa86-51116ae55021",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tfidf_df['sentiment_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cafdd-bd2c-4669-b427-0ece258ad08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81cc352-ec46-4e05-914a-f76cea1129ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ecf41-f22d-42bd-a657-f1fcc2867e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5abdfa1-545a-4573-b719-57a3e43246c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47ebcb-c846-45c8-9735-c2127e225005",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e31fb5-9535-4134-bb75-297b41687633",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960977d-b30e-497d-8fa5-8522d6585134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d271919b-c432-4d82-b811-f3b6b1f9e737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1ec7a78-3136-4511-9a40-23e4cd19627f",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1ef10-08c2-49fd-a4d5-ba05d012adb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b54c0d32-ff96-4958-b410-40d7703cd5d7",
   "metadata": {},
   "source": [
    "# Model 1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3060a44-2996-4e6e-9307-46ddd2687b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aaa57c-f70f-4801-9a8a-3842b28f306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression(max_iter=1000, random_state=42, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f6482-e212-43c4-8637-8af6839d9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11694f1-4f67-4ef9-ad7e-705aea2e2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12ad53-0928-45ee-b97b-7c8e8fbcd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "print(\"Accuracy  and classification report of LogisticRegression: \")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81e160-19d8-4073-bc9e-b625208a3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../models/logistic_model.pkl\", \"wb\") as f:\n",
    "#     dill.dump(model1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd5857-4d5b-49d2-bfc1-4fe7448421ae",
   "metadata": {},
   "source": [
    "# Model 2: SVM (svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0983e07-6f02-48e4-8b57-5008be0b5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import dill\n",
    "\n",
    "# Create the SVM model\n",
    "# For multi-class classification, 'ovr' (one-vs-rest) is default\n",
    "model_svm = SVC(kernel='linear', probability=True, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_svm.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy and classification report of SVM: \")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the trained SVM model\n",
    "# with open(\"../models/svm_model.pkl\", \"wb\") as f:\n",
    "#     dill.dump(model_svm, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35056753-3071-44f7-a8ff-5fb90bdc5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import dill\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089cbe8-34fa-44a4-8c52-c20fbf8565f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'kernel': ['linear'], # Kernels to try\n",
    "    'C': [0.1, 1,]                         # Regularization                              \n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b20336-abe3-4291-9a22-c220f0916440",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(class_weight='balanced', probability=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svc,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',       # Optimize for accuracy\n",
    "    cv=5,                     # 5-fold cross-validation\n",
    "    n_jobs=-1,                # Use all cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f825f-ae91-485c-9fe7-d7974d216aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "best_svc = grid_search.best_estimator_\n",
    "y_pred = best_svc.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60531da4-9152-4ec9-b66b-71dcf381102d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e05c976f-9ae9-4a8b-bdb5-d31842cc8378",
   "metadata": {},
   "source": [
    "# Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b845f-6cbf-4ef8-8fa9-f892d95ba7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model2_rf = RandomForestClassifier()\n",
    "\n",
    "model2_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = model2_rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy  and classification report of Random forest: \")\n",
    "print(f\"Accuracy: {accuracy_score(y_test,y_pred2)}\")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd54169-ab41-400c-9dfa-f871b2a4b883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "568ce5fc-9cc5-4f91-ad9e-95d5c08b44b7",
   "metadata": {},
   "source": [
    "# Sentiment Prediction on New Input Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c68fe2-c2be-4454-8bd2-c7596afca68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878423ff-600f-4266-8630-61f0d05c543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import dill\n",
    "class TextCleaner:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def clean(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'<.*?>', '', text)            # remove HTML\n",
    "        text = re.sub(r'http\\S+|www\\S+', '', text)   # remove URLs\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)         # keep only letters\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()     # remove extra spaces\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83baaf-41a6-499b-847a-4f677a696c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4afcb7-5f8f-4f9b-b2a9-dbbdedd8f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTokenizerStopwordsRemover:\n",
    "    def __init__(self):\n",
    "        # Initialize stopwords inside the class\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def tokenize_and_remove_stopwords(self, text):\n",
    "        \n",
    "\n",
    "        tokens = word_tokenize(text)\n",
    "        return [token for token in tokens if token.lower() not in self.stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4140a-25e7-416a-8428-f56a46a43bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0852d-bd02-4b70-88cd-bd5cd6095401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "class Lemmatization:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "    def lemmatize_tokens_spacy(self,tokens):\n",
    "        doc = self.nlp(\" \".join(tokens))   # join tokens back into a sentence for spaCy\n",
    "        return [token.lemma_ for token in doc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc68c6e-339b-4c23-8488-32a5a3c5af92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963fe19-bb87-4697-bbb0-49772fc68716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(test_text):\n",
    "    print(f\"Input Text: [{test_text}]\\n\")\n",
    "\n",
    "    # Load pickled preprocessors and model\n",
    "    cleaner = TextCleaner()\n",
    "    tokenizer_stopword_remover = TextTokenizerStopwordsRemover()\n",
    "    lemmatizer = Lemmatization()\n",
    "    \n",
    "   \n",
    "    with open('../backend/models/tfidf_vectorizer.pkl', 'rb') as f:\n",
    "        tfidf = dill.load(f)\n",
    "    with open('../backend/models/logistic_model.pkl', 'rb') as f:\n",
    "        model = dill.load(f)\n",
    "\n",
    "    # Step 1: Clean text\n",
    "    cleaned_text = cleaner.clean(test_text)\n",
    "    print(f\"Cleaned text: [{cleaned_text}]\\n\")\n",
    "\n",
    "    # Step 2: Tokenize & remove stopwords\n",
    "    tokens = tokenizer_stopword_remover.tokenize_and_remove_stopwords(cleaned_text)\n",
    "    print(f\"Tokens after stopword removal: [{tokens}]\\n\")\n",
    "\n",
    "    # Step 3: Lemmatize tokens\n",
    "    lemmatized_tokens = lemmatizer.lemmatize_tokens_spacy(tokens)\n",
    "    print(f\"Lemmatized tokens: [{lemmatized_tokens}]\\n\")\n",
    "\n",
    "    # Step 4: Join tokens and convert to TF-IDF vector\n",
    "    final_text = ' '.join(lemmatized_tokens)\n",
    "    print(f\"Final preprocessed text: [{final_text}]\\n\")\n",
    "    vector = tfidf.transform([final_text])\n",
    "\n",
    "    # Step 5: Predict\n",
    "    predicted_class = model.predict(vector)[0]\n",
    "    sentiment_labels = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "    predicted_sentiment = sentiment_labels[predicted_class]\n",
    "\n",
    "    print(f\"Predicted Sentiment: {predicted_sentiment}\\n\")\n",
    "    return predicted_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae5d93-2633-4499-a661-75d8896ae739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0603b2-dbac-40e1-8806-1af1a7e7ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"The product was horrible and disappointing.\"\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7aa77-2f75-4d31-88c9-cd56ec780e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f602305-10d5-4d05-80dc-edecaf8fcb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"The product is okay, nothing special but works fine.\"\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d34627-81b4-4fd3-aeec-eb64ac08c3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6505aa-ea89-4288-a6a1-0c721fb9c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"This is the best product \"\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b841e5b-fc19-4e47-ac34-10bb7ae6132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"The product is not good okay\"\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26a738b-d21a-4ca8-b2dc-f0c485a8251e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
